{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53c9fb6f-194e-4519-bde0-0c29d14bf0b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter WLSAccessID\n",
      "Set parameter WLSSecret\n",
      "Set parameter LicenseID to value 2586688\n",
      "Academic license 2586688 - for non-commercial use only - registered to ru___@ucsd.edu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<gurobipy.Env, Parameter changes: WLSAccessID=(user-defined), WLSSecret=(user-defined), LicenseID=2586688>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "from itertools import product, combinations\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gurobipy as gb\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "# WLS credentials\n",
    "WLSACCESSID = 'ccc2c36a-db14-4956-b2e3-60adc45e9957'\n",
    "WLSSECRET = '1e0e3dbf-7933-44dc-8f81-e0482ded7ac8'\n",
    "LICENSEID = 2586688\n",
    "\n",
    "# Create the Gurobi environment with parameters\n",
    "env = gb.Env(empty=True)  # Start with an empty environment\n",
    "env.setParam('WLSACCESSID', WLSACCESSID)\n",
    "env.setParam('WLSSECRET', WLSSECRET)\n",
    "env.setParam('LICENSEID', LICENSEID)\n",
    "env.start() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a944963-dbcf-4cd2-abc2-005ddb9201cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'ap_ib', 'calculus', 'counselors', 'frpl_rate',\n",
       "       'frac_sat_act', 'n_sat_act', 'n_A_m', 'n_A_f', 'n_B_m', 'n_B_f',\n",
       "       'n_C_m', 'n_C_f', 'n_D_m', 'n_D_f', 'n_E_m', 'n_E_f', 'n_F_m', 'n_F_f',\n",
       "       'n_G_m', 'n_G_f', 'n_A', 'n_B', 'n_C', 'n_D', 'n_E', 'n_F', 'n_G',\n",
       "       'frac_A_m', 'frac_A_f', 'frac_B_m', 'frac_B_f', 'frac_C_m', 'frac_C_f',\n",
       "       'frac_D_m', 'frac_D_f', 'frac_E_m', 'frac_E_f', 'frac_F_m', 'frac_F_f',\n",
       "       'frac_G_m', 'frac_G_f', 'frac_A', 'frac_B', 'frac_C', 'frac_D',\n",
       "       'frac_E', 'frac_F', 'frac_G', 'n_sat_act_A_m', 'n_sat_act_A_f',\n",
       "       'n_sat_act_B_m', 'n_sat_act_B_f', 'n_sat_act_C_m', 'n_sat_act_C_f',\n",
       "       'n_sat_act_D_m', 'n_sat_act_D_f', 'n_sat_act_E_m', 'n_sat_act_E_f',\n",
       "       'n_sat_act_F_m', 'n_sat_act_F_f', 'n_sat_act_G_m', 'n_sat_act_G_f',\n",
       "       'n_sat_act_A', 'n_sat_act_B', 'n_sat_act_C', 'n_sat_act_D',\n",
       "       'n_sat_act_E', 'n_sat_act_F', 'n_sat_act_G', 'frac_sat_act_A_m',\n",
       "       'frac_sat_act_A_f', 'frac_sat_act_B_m', 'frac_sat_act_B_f',\n",
       "       'frac_sat_act_C_m', 'frac_sat_act_C_f', 'frac_sat_act_D_m',\n",
       "       'frac_sat_act_D_f', 'frac_sat_act_E_m', 'frac_sat_act_E_f',\n",
       "       'frac_sat_act_F_m', 'frac_sat_act_F_f', 'frac_sat_act_G_m',\n",
       "       'frac_sat_act_G_f', 'frac_sat_act_A', 'frac_sat_act_B',\n",
       "       'frac_sat_act_C', 'frac_sat_act_D', 'frac_sat_act_E', 'frac_sat_act_F',\n",
       "       'frac_sat_act_G', 'total_students', 'latitude', 'longitude'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('features.csv')\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8ef3c6-bf77-455d-9bd0-99890696f4da",
   "metadata": {},
   "source": [
    "# Explanation of Dataset Features\n",
    "\n",
    "### General Information\n",
    "- **`Unnamed: 0`**: Likely an index column automatically generated during data import. If not meaningful, it can be dropped.\n",
    "- **`latitude`**: Latitude of the school, used for geographic analysis.\n",
    "- **`longitude`**: Longitude of the school, used for geographic analysis.\n",
    "\n",
    "---\n",
    "\n",
    "### Input Features (`X`)\n",
    "These represent characteristics of schools that may affect student outcomes:\n",
    "- **`ap_ib`**: Indicator or count of students enrolled in Advanced Placement (AP) or International Baccalaureate (IB) programs. Higher values indicate better academic resources or rigor.\n",
    "- **`calculus`**: Indicator or count of students enrolled in Calculus courses, which may act as a proxy for advanced math preparation.\n",
    "- **`counselors`**: Number of counselors available at the school, potentially influencing college readiness and student support.\n",
    "- **`frpl_rate`**: Percentage of students eligible for Free or Reduced-Price Lunch (FRPL), a socioeconomic indicator where higher values suggest greater economic disadvantage.\n",
    "\n",
    "---\n",
    "\n",
    "### Outcome Variables (`y`)\n",
    "These represent the target outcomes or results that the model aims to improve:\n",
    "- **`frac_sat_act`**: Fraction of students who took the SAT or ACT, a measure of college readiness.\n",
    "- **`n_sat_act`**: Count of students who took the SAT or ACT.\n",
    "\n",
    "---\n",
    "\n",
    "### Demographic-Specific Counts (`n_*`)\n",
    "These represent the **count of students** in specific demographic categories:\n",
    "- **By Gender and Category (e.g., `n_A_m`, `n_A_f`)**:\n",
    "  - `n_A_m`: Number of male students in demographic category A.\n",
    "  - `n_A_f`: Number of female students in demographic category A.\n",
    "  - Categories B through G follow the same format.\n",
    "- **Aggregated by Category (e.g., `n_A`)**:\n",
    "  - Total number of students in category A, regardless of gender.\n",
    "  - Categories B through G are aggregated similarly.\n",
    "\n",
    "---\n",
    "\n",
    "### Demographic-Specific Fractions (`frac_*`)\n",
    "These represent the **proportion of students** in specific demographic categories:\n",
    "- **By Gender and Category (e.g., `frac_A_m`, `frac_A_f`)**:\n",
    "  - `frac_A_m`: Fraction of male students in demographic category A.\n",
    "  - `frac_A_f`: Fraction of female students in demographic category A.\n",
    "  - Categories B through G follow the same format.\n",
    "- **Aggregated by Category (e.g., `frac_A`)**:\n",
    "  - Total fraction of students in category A, regardless of gender.\n",
    "  - Categories B through G are aggregated similarly.\n",
    "\n",
    "---\n",
    "\n",
    "### SAT/ACT-Specific Counts and Fractions\n",
    "These measure SAT/ACT participation within specific demographic categories:\n",
    "\n",
    "#### Counts (`n_sat_act_*`):\n",
    "- **By Gender and Category** (e.g., `n_sat_act_A_m`):\n",
    "  - Count of male students in category A who took the SAT/ACT.\n",
    "- **Aggregated by Category** (e.g., `n_sat_act_A`):\n",
    "  - Total count of students in category A who took the SAT/ACT.\n",
    "- Categories B through G follow the same format.\n",
    "\n",
    "#### Fractions (`frac_sat_act_*`):\n",
    "- **By Gender and Category** (e.g., `frac_sat_act_A_m`):\n",
    "  - Fraction of male students in category A who took the SAT/ACT.\n",
    "- **Aggregated by Category** (e.g., `frac_sat_act_A`):\n",
    "  - Total fraction of students in category A who took the SAT/ACT.\n",
    "- Categories B through G follow the same format.\n",
    "\n",
    "---\n",
    "\n",
    "### Other Features\n",
    "- **`total_students`**: Total number of students in the school, regardless of demographic categories. Useful for normalizing counts or computing participation rates.\n",
    "\n",
    "---\n",
    "\n",
    "### Summary of Feature Groups\n",
    "\n",
    "| **Feature Group**             | **Description**                                               |\n",
    "|-------------------------------|-------------------------------------------------------------|\n",
    "| General Information           | School index, latitude, longitude                           |\n",
    "| Input Features                | Academic resources, socioeconomic data (`ap_ib`, `frpl_rate`) |\n",
    "| Outcome Variables             | SAT/ACT participation metrics                               |\n",
    "| Demographic Counts (`n_*`)    | Counts of students by demographic category and gender       |\n",
    "| Demographic Fractions (`frac_*`) | Proportions of students by demographic category and gender  |\n",
    "| SAT/ACT Counts and Fractions  | Participation counts and fractions by demographic group     |\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9130ad7f-7a20-4cfe-bd47-f4536f954037",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Constants\n",
    "SOCIAL_CATEGORIES = ['A', 'B', 'C', 'D', 'E', 'F', 'G']\n",
    "BUDGET = 100\n",
    "TAU_VALUES = [0.566, None]  # Define fairness constraints for optimization\n",
    "\n",
    "# Data Preparation\n",
    "df = pd.read_csv('features.csv')\n",
    "X_columns = ['frpl_rate', 'calculus', 'ap_ib', 'counselors']\n",
    "count_columns = [f'n_{category}' for category in SOCIAL_CATEGORIES]\n",
    "frac_columns = [f'frac_{category}' for category in SOCIAL_CATEGORIES]\n",
    "\n",
    "X = df[X_columns]\n",
    "A_frac = df[frac_columns]\n",
    "y_train = df['frac_sat_act'].values\n",
    "\n",
    "neighbor_distance_matrix = np.load('neighbor_distance_matrix.npy')\n",
    "neighbor_index_matrix = np.load('neighbor_index_matrix.npy')\n",
    "\n",
    "ap_ib = X['ap_ib'].values\n",
    "calculus = X['calculus'].values\n",
    "counselors = X['counselors'].values\n",
    "n = len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e7f6aec-05b2-4ecf-a62a-ccb26e408ddd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(490, 4)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c41883c-9fcf-47fa-bbc5-9e00ec2e4971",
   "metadata": {},
   "outputs": [],
   "source": [
    "AP_IB = X['ap_ib'].values\n",
    "COUNSELORS = X['counselors'].values\n",
    "FRPL = np.ones_like(X['frpl_rate'].values)\n",
    "A_FRAC = df[frac_columns]\n",
    "A_MATRIX = A_FRAC.values\n",
    "\n",
    "\n",
    "\n",
    "NEIGHBOR_INDEX_MATRIX = np.load('neighbor_index_matrix.npy')\n",
    "NEIGHBOR_DISTANCE_MATRIX = np.load('neighbor_distance_matrix.npy')\n",
    "NUM_SCHOOLS = X.shape[0]\n",
    "# weight_df = pd.read_csv('params_7_disagg.csv', index_col=0)\n",
    "# WEIGHT_MATRIX = weight_df.values\n",
    "\n",
    "NUM_NEIGHBORS = NEIGHBOR_INDEX_MATRIX.shape[1]\n",
    "intervention_sample_spaces = [(0, 1)] * NUM_NEIGHBORS\n",
    "POSSIBLE_INTERVENTIONS_MATRIX = np.array(list(\n",
    "    product(*intervention_sample_spaces)\n",
    "))\n",
    "NUM_POSSIBLE_INTERVENTIONS = POSSIBLE_INTERVENTIONS_MATRIX.shape[0]\n",
    "\n",
    "BUDGET = 100\n",
    "\n",
    "NUM_CATEGORIES = 28\n",
    "CATEGORIES = list(range(NUM_CATEGORIES))\n",
    "CATEGORY_PAIRS = list(combinations(CATEGORIES, 2))\n",
    "\n",
    "DEMOGRAPHIC_COUNTERFACTUALS = [0, 1]\n",
    "NUM_COUNTERFACTUALS = len(DEMOGRAPHIC_COUNTERFACTUALS)\n",
    "\n",
    "TOTAL_STUDENTS = df['total_students'].values\n",
    "R_COUNTS = df[count_columns].values\n",
    "R_COUNTS_TOTAL = R_COUNTS.sum(axis=0)\n",
    "\n",
    "CALCULUS = X['calculus']\n",
    "A_DIMENSION = A_MATRIX.shape[1]\n",
    "\n",
    "WHETHER_OR_NOT_CALCULUS_GIVEN_INTERFERENCE = np.max(\n",
    "    NEIGHBOR_DISTANCE_MATRIX * CALCULUS.values, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cef73972-c17d-45ab-8564-4bc47017bf14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.06676548,  0.02920318,  0.27690293, -0.1496839 ,  0.6896188 ,\n",
       "         1.84418092, -0.37517525]),\n",
       " array([ 0.14725533,  0.11735532, -0.16410716,  0.05501886, -1.68741278,\n",
       "        -0.61907302, -3.03710195]),\n",
       " array([ 0.00873755, -0.0087489 , -0.0043426 ,  0.01557128, -0.30437838,\n",
       "        -0.05114738,  0.0774586 ]),\n",
       " array([ 0.09178179,  0.13514781,  0.21394424,  0.46154045,  3.30620549,\n",
       "        -0.65855919,  4.18574581]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate adjusted features for regression model\n",
    "def compute_adjusted_features(feature_values, A_frac, neighbor_distance_matrix):\n",
    "    max_neighbor_influence = np.max(neighbor_distance_matrix * feature_values.T, axis=1).reshape(n, 1)\n",
    "    return A_frac * max_neighbor_influence\n",
    "\n",
    "a_max_Sij_Pj = compute_adjusted_features(ap_ib, A_frac, neighbor_distance_matrix)\n",
    "a_max_Sij_Cj = compute_adjusted_features(calculus, A_frac, neighbor_distance_matrix)\n",
    "a_Fj = A_frac * counselors.reshape(n, 1)\n",
    "\n",
    "# Combine features for regression model\n",
    "X_train = np.concatenate((a_max_Sij_Pj, a_max_Sij_Cj, a_Fj, A_frac), axis=1)\n",
    "\n",
    "# Train linear regression model\n",
    "linmod = LinearRegression(fit_intercept=False).fit(X_train, y_train)\n",
    "model_weights = linmod.coef_\n",
    "param_dims = len(SOCIAL_CATEGORIES)\n",
    "\n",
    "# Extract regression weights\n",
    "weight_dict = {\n",
    "    'alpha': model_weights[param_dims:param_dims*2],\n",
    "    'beta': model_weights[:param_dims],\n",
    "    'gamma': model_weights[param_dims*2:param_dims*3],\n",
    "    'theta': model_weights[-param_dims:]\n",
    "}\n",
    "params = pd.DataFrame(weight_dict)\n",
    "\n",
    "ALPHA, BETA, GAMMA, THETA = (params['alpha'].values, params['beta'].values, \n",
    "                             params['gamma'].values, params['theta'].values)\n",
    "\n",
    "ALPHA, BETA, GAMMA, THETA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0b9fe27-e58a-4ffa-ab7c-d5af3cef0791",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimization Helpers\n",
    "def calculate_expected_impact(index, intervention_array, demographic_vector):\n",
    "    nearest_neighbors = neighbor_index_matrix[index, :]\n",
    "    neighbor_distances = neighbor_distance_matrix[index, nearest_neighbors]\n",
    "\n",
    "    calculus_term = np.dot(demographic_vector, ALPHA) * np.max(neighbor_distances * intervention_array)\n",
    "    ap_ib_term = np.dot(demographic_vector, BETA) * np.max(neighbor_distances * ap_ib[nearest_neighbors])\n",
    "    counselors_term = np.dot(demographic_vector, GAMMA) * counselors[index]\n",
    "    race_term = np.dot(demographic_vector, THETA)\n",
    "\n",
    "    impact = calculus_term + ap_ib_term + counselors_term + race_term\n",
    "    return max(min(impact, 1), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5bd8a30-c7c3-4aa6-af79-e537bb1ea0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_all_possible_impacts(index, demographic_vector, POSSIBLE_INTERVENTIONS_MATRIX):\n",
    "    possible_impacts = np.empty(len(POSSIBLE_INTERVENTIONS_MATRIX))\n",
    "    for k, intervention_array in enumerate(POSSIBLE_INTERVENTIONS_MATRIX):\n",
    "        possible_impacts[k] = calculate_expected_impact(index, intervention_array, demographic_vector)\n",
    "    return possible_impacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33fbb53-9159-479b-8647-adeea42e551e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running optimization for tau=0.566\n",
      "Gurobi Optimizer version 12.0.0 build v12.0.0rc1 (linux64 - \"Ubuntu 22.04.4 LTS\")\n",
      "\n",
      "CPU model: AMD EPYC 7662 64-Core Processor, instruction set [SSE2|AVX|AVX2]\n",
      "Thread count: 128 physical cores, 256 logical processors, using up to 32 threads\n",
      "\n",
      "Academic license 2586688 - for non-commercial use only - registered to ru___@ucsd.edu\n",
      "Optimize a model with 192081 rows, 31850 columns and 627626 nonzeros\n",
      "Model fingerprint: 0xa5000302\n",
      "Variable types: 31360 continuous, 490 integer (490 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e-06, 1e+00]\n",
      "  Objective range  [6e-02, 6e-01]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [6e-01, 1e+02]\n",
      "Presolve removed 1051 rows and 0 columns\n",
      "Presolve time: 0.26s\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.36 seconds (0.37 work units)\n",
      "Thread count was 1 (of 256 available processors)\n",
      "\n",
      "Solution count 0\n",
      "\n",
      "Model is infeasible or unbounded\n",
      "Best objective -, best bound -, gap -\n",
      "Optimization failed for tau=0.566: Optimization failed.\n",
      "Running optimization for tau=None\n",
      "Gurobi Optimizer version 12.0.0 build v12.0.0rc1 (linux64 - \"Ubuntu 22.04.4 LTS\")\n",
      "\n",
      "CPU model: AMD EPYC 7662 64-Core Processor, instruction set [SSE2|AVX|AVX2]\n",
      "Thread count: 128 physical cores, 256 logical processors, using up to 32 threads\n",
      "\n",
      "Academic license 2586688 - for non-commercial use only - registered to ru___@ucsd.edu\n",
      "Optimize a model with 188651 rows, 31850 columns and 408170 nonzeros\n",
      "Model fingerprint: 0x3f2268fb\n",
      "Variable types: 31360 continuous, 490 integer (490 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [6e-02, 6e-01]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 1e+02]\n",
      "Found heuristic solution: objective 123.1486903\n",
      "Presolve time: 0.62s\n",
      "Presolved: 188651 rows, 31850 columns, 408170 nonzeros\n",
      "Variable types: 31360 continuous, 490 integer (490 binary)\n",
      "\n",
      "Deterministic concurrent LP optimizer: primal and dual simplex (primal and dual model)\n",
      "Showing primal log only...\n",
      "\n",
      "Root relaxation presolved: 188651 rows, 31850 columns, 408170 nonzeros\n",
      "\n",
      "\n",
      "Root simplex log...\n",
      "\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "   28776    1.2897348e+02   4.429037e-02   3.900407e+07      5s\n",
      "Concurrent spin time: 0.22s\n",
      "\n",
      "Solved with dual simplex\n",
      "\n",
      "Root relaxation: objective 1.340295e+02, 31647 iterations, 5.93 seconds (3.37 work units)\n",
      "Total elapsed time = 10.04s (DegenMoves)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0  134.02947    0  422  123.14869  134.02947  8.84%     -   12s\n",
      "H    0     0                     126.5647704  134.02947  5.90%     -   12s\n",
      "H    0     0                     126.8706385  134.02947  5.64%     -   13s\n",
      "H    0     0                     127.0852061  134.02947  5.46%     -   13s\n",
      "H    0     0                     127.4097545  134.02947  5.20%     -   13s\n",
      "H    0     0                     127.4771135  134.02947  5.14%     -   13s\n",
      "H    0     0                     127.5121374  134.02947  5.11%     -   14s\n",
      "H    0     0                     127.5427864  134.02947  5.09%     -   31s\n",
      "H    0     0                     127.5478493  134.02947  5.08%     -   31s\n",
      "H    0     0                     127.5484110  134.02947  5.08%     -   31s\n",
      "H    0     0                     127.5487312  134.02947  5.08%     -   31s\n",
      "H    0     0                     127.5631690  134.02947  5.07%     -   31s\n",
      "H    0     0                     127.5878089  134.02947  5.05%     -   31s\n",
      "H    0     0                     127.5884063  134.02947  5.05%     -   31s\n",
      "H    0     0                     127.5935144  134.02947  5.04%     -   33s\n",
      "H    0     0                     127.6130982  134.02947  5.03%     -   33s\n",
      "H    0     0                     127.6163243  134.02947  5.03%     -   36s\n",
      "H    0     0                     127.6790917  134.02947  4.97%     -   41s\n",
      "H    0     0                     127.9827422  134.02947  4.72%     -   42s\n",
      "H    0     0                     128.0533140  134.02947  4.67%     -   42s\n",
      "H    0     0                     128.9919946  134.02947  3.91%     -   43s\n",
      "H    0     0                     129.1435439  134.02947  3.78%     -   43s\n",
      "     0     0  133.44285    0  306  129.14354  133.44285  3.33%     -   56s\n",
      "H    0     0                     130.0812108  133.44177  2.58%     -   57s\n",
      "H    0     0                     130.1603063  133.44177  2.52%     -   57s\n",
      "H    0     0                     130.4514332  133.44177  2.29%     -   57s\n",
      "H    0     0                     130.4966209  133.44177  2.26%     -   57s\n",
      "H    0     0                     130.4993906  133.44177  2.25%     -   57s\n",
      "H    0     0                     130.7230688  133.44177  2.08%     -   57s\n",
      "H    0     0                     130.7727734  133.44177  2.04%     -   58s\n",
      "     0     0  133.42973    0  306  130.77277  133.42973  2.03%     -   65s\n",
      "     0     0  132.31929    0  249  130.77277  132.31929  1.18%     -   71s\n",
      "H    0     0                     130.7731911  132.31766  1.18%     -   72s\n",
      "H    0     0                     130.7793518  132.31766  1.18%     -   72s\n",
      "     0     0  132.24212    0  248  130.77935  132.24212  1.12%     -   73s\n",
      "     0     0  132.23757    0  248  130.77935  132.23757  1.12%     -   73s\n",
      "     0     0  132.23732    0  248  130.77935  132.23732  1.11%     -   73s\n",
      "     0     0  131.77900    0  221  130.77935  131.77900  0.76%     -   76s\n",
      "H    0     0                     130.8311992  131.75858  0.71%     -   77s\n",
      "H    0     0                     130.9103739  131.75858  0.65%     -   78s\n",
      "H    0     0                     130.9122549  131.75858  0.65%     -   78s\n",
      "H    0     0                     130.9479632  131.75858  0.62%     -   78s\n",
      "H    0     0                     130.9479980  131.75858  0.62%     -   78s\n",
      "     0     0  131.69495    0  200  130.94800  131.69495  0.57%     -   79s\n",
      "     0     0  131.68561    0  201  130.94800  131.68561  0.56%     -   79s\n",
      "     0     0  131.68276    0  200  130.94800  131.68276  0.56%     -   79s\n",
      "     0     0  131.68276    0  200  130.94800  131.68276  0.56%     -   80s\n"
     ]
    }
   ],
   "source": [
    "# Optimization Routine\n",
    "def optimize_interventions(tau_value, A_frac, POSSIBLE_INTERVENTIONS_MATRIX):\n",
    "    print(f'Running optimization for tau={tau_value}')\n",
    "    model = gb.Model(env=env)\n",
    "\n",
    "    interventions = model.addVars(n, vtype=gb.GRB.BINARY, name=\"interventions\")\n",
    "    model.addConstr(sum(interventions.values()) <= BUDGET, \"budget_constraint\")\n",
    "\n",
    "    def add_auxiliary_constraints(index):\n",
    "        demographic_vector = A_frac.values[index, :]\n",
    "        factual_impacts = calculate_all_possible_impacts(index, demographic_vector, POSSIBLE_INTERVENTIONS_MATRIX)\n",
    "\n",
    "        auxiliary_vars = model.addVars(\n",
    "            len(factual_impacts), obj=factual_impacts, vtype=gb.GRB.CONTINUOUS\n",
    "        )\n",
    "        model.update()\n",
    "\n",
    "        for j, intervention in enumerate(POSSIBLE_INTERVENTIONS_MATRIX):\n",
    "            for k, neighbor in enumerate(neighbor_index_matrix[index]):\n",
    "                if intervention[k] == 1:\n",
    "                    model.addConstr(auxiliary_vars[j] <= interventions[neighbor])\n",
    "                else:\n",
    "                    model.addConstr(auxiliary_vars[j] <= 1 - interventions[neighbor])\n",
    "        model.addConstr(sum(auxiliary_vars.values()) == 1)\n",
    "\n",
    "        if tau_value is not None:\n",
    "            for group_idx in range(A_frac.shape[1]):\n",
    "                group_impact_diff = calculate_all_possible_impacts(index, np.eye(A_frac.shape[1])[group_idx], POSSIBLE_INTERVENTIONS_MATRIX) - factual_impacts\n",
    "                model.addConstr(\n",
    "                    sum(auxiliary_vars[j] * group_impact_diff[j] for j in range(len(factual_impacts))) <= tau_value\n",
    "                )\n",
    "\n",
    "    for index in range(n):\n",
    "        add_auxiliary_constraints(index)\n",
    "\n",
    "    model.setObjective(model.getObjective(), gb.GRB.MAXIMIZE)\n",
    "    model.optimize()\n",
    "\n",
    "    if model.status == gb.GRB.OPTIMAL:\n",
    "        return np.array([interventions[i].X for i in range(n)]).astype(bool)\n",
    "    else:\n",
    "        raise RuntimeError(\"Optimization failed.\")\n",
    "\n",
    "# Run optimization for each tau value\n",
    "for tau_value in TAU_VALUES:\n",
    "    try:\n",
    "        optimal_interventions = optimize_interventions(tau_value, A_frac, POSSIBLE_INTERVENTIONS_MATRIX)\n",
    "        print(f\"Optimal interventions: {np.where(optimal_interventions)}\")\n",
    "    except RuntimeError as e:\n",
    "        print(f\"Optimization failed for tau={tau_value}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aafc9875-2deb-495a-a9b0-5dc88119da00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc475b3-0e43-4c50-8492-339a995bfc54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
